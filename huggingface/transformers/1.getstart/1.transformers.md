Transformers
================
用于PyTorch、TensorFlow和JAX的最先进的机器学习框架。

Transformers提供了APIs和各种工具来轻松下载和训练最先进的预训练模型。使用预训练的模型可以减少你的计算成本、碳足迹，并节省你从头训练模型所需的时间和资源。这些模型支持不同模式下的常见任务，如：

- **自然语言处理：** 文本分类、命名实体识别、问题回答、语言建模、总结、翻译、多选和文本生成。
- **计算机视觉：** 图像分类、物体检测和分割。
- **音频：** 自动语音识别和音频分类。
- **多模态：** 表格问题回答，光学字符识别，从扫描文件中提取信息，视频分类，以及视觉问题回答。

Transformers支持PyTorch、TensorFlow和JAX之间的框架互操作性。这为在模型的每个阶段使用不同的框架提供了灵活性；在一个框架中用很少的代码训练一个模型，并在另一个框架中加载它进行推理。模型也可以导出为ONNX和TorchScript等格式，以便在生产环境中部署。

## 内容
该文件分为五个部分：
- **开始** 提供了一个快速的使用指导和安装说明，以便启动和运行。
- **教程** 如果你是一个初学者，教程是一个很好的开始。本节将帮助你获得开始使用库所需的基本技能。
- **操作指南** 向你展示如何实现一个特定的目标，比如为语言建模微调一个预训练的模型，或者如何编写和分享一个自定义模型。
- **概念性指南** 提供更多关于模型、任务和Transformers设计理念背后的基本概念、想法的讨论和解释。
- **API** 详细描述了每个模块、类和函数的参数和用法。
> - **MAIN CLASSES** 详细介绍了最重要的类，如配置、模型、标记器和管道。
> - **MODELS** 详细介绍了库中实现的每个模型相关的类和函数。
> - **INTERNAL HELPERS** 详细介绍了内部使用的实用类和函数。