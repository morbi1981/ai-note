通过AutoClass加载预训练的实例
===
由于有这么多不同的Transformer架构，为你的checkpoint创建一个架构可能是一个挑战。作为Transformers核心理念的一部分，库可以容易、简单和灵活使用，AutoClass自动推断并从一个给定的checkpoint加载正确的架构。from_pretrained()方法可以让你快速加载任何架构的预训练模型，这样你就不必投入时间和资源从头开始训练模型。产生这种类型的checkpoint无关的代码意味着如果你的代码对一个checkpoint有效，它也会对另一个checkpoint有效--只要它是为类似的任务训练的--即使架构不同。

> 请记住，架构指的是模型的骨架，而checkpoint是特定架构的权重。例如，BERT是一个架构，而bert-base-uncased是一个checkpoint。模型是一个通用术语，可以指架构或checkpoint。

在本教程中，学习如何：

* 加载一个预训练的标记器。
* 加载一个预训练的图像处理器。
* 加载一个预先训练好的特征提取器。
* 加载一个预训练的处理器。
* 加载一个预训练的模型。

## AutoTokenizer(自动标记器)