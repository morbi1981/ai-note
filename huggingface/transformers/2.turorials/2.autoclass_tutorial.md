通过AutoClass加载预训练的实例
===
由于有这么多不同的Transformer架构，为你的checkpoint创建一个架构可能是一个挑战。作为Transformers核心理念的一部分，库可以容易、简单和灵活使用，AutoClass自动推断并从一个给定的checkpoint加载正确的架构。from_pretrained()方法可以让你快速加载任何架构的预训练模型，这样你就不必投入时间和资源从头开始训练模型。产生这种类型的checkpoint无关的代码意味着如果你的代码对一个checkpoint有效，它也会对另一个checkpoint有效--只要它是为类似的任务训练的--即使架构不同。

> 请记住，架构指的是模型的骨架，而checkpoint是特定架构的权重。例如，BERT是一个架构，而bert-base-uncased是一个checkpoint。模型是一个通用术语，可以指架构或checkpoint。

在本教程中，学习如何：

* 加载一个预训练的标记器。
* 加载一个预训练的图像处理器。
* 加载一个预先训练好的特征提取器。
* 加载一个预训练的处理器。
* 加载一个预训练的模型。

## 自动标记器(AutoTokenizer)

几乎每个NLP任务都是从标记器开始的。标记器将你的输入转换为可由模型处理的格式。

用AutoTokenizer.from_pretrained()加载一个标记器：

```
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
```

然后对你的输入进行标记化，如下所示：

```
sequence = "In a hole in the ground there lived a hobbit."
print(tokenizer(sequence))
```
```
{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], 
 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
```

## 自动图像处理程序（AutoImageProcessor）

对于视觉任务，一个图像处理器将图像处理成正确的输入格式。

```
from transformers import AutoImageProcessor

image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224")
```

## 自动特征提取器（AutoFeatureExtractor）

对于音频任务，一个特征提取器将音频信号处理成正确的输入格式。

用AutoFeatureExtractor.from_pretrained()加载一个特征提取器：

```
from transformers import AutoFeatureExtractor

feature_extractor = AutoFeatureExtractor.from_pretrained(
    "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)
```

## 自动处理程序（AutoProcessor）

多模态任务需要一个结合两类预处理工具的处理器。例如，LayoutLMV2模型需要一个图像处理器来处理图像，一个标记器来处理文本；一个处理器结合了这两种工具。

用AutoProcessor.from_pretrained()加载一个处理器：

```
from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("microsoft/layoutlmv2-base-uncased")
```

## 自动模型（AutoModel）

最后，AutoModelFor类让你为一个给定的任务加载一个预训练的模型（关于可用任务的完整列表，见[这里](https://huggingface.co/docs/transformers/model_doc/auto)）。

例如，用AutoModelForSequenceClassification.from_pretrained()加载一个用于序列分类的模型：

```
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
```

很容易重复使用同一个检查点，为不同的任务加载一个架构：

```
from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained("distilbert-base-uncased")
```

一般来说，我们推荐使用AutoTokenizer类和AutoModelFor类来加载模型的预训练实例。这将确保你每次都能加载正确的架构。在下一个教程中，学习如何使用你新加载的标记器、图像处理器、特征提取器和处理器来预处理数据集，以便进行微调。

---
V4.30.0